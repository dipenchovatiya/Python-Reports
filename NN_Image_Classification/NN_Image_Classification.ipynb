{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=navy>  Report 6: Training a neural net for image classification. </font>\n",
    "#### <font color=navy>  Submitted By :  Dipen Chovatiya </font>\n",
    "#### <font color=navy>  Date: 11/20/2018 </font>\n",
    "\n",
    "## <font color=navy> l. Introduction </font>\n",
    "In this report we will try to train a neural network for images of  handwritten digits using Python. There are couple of ways to to achieve this goal such as Feature Engineering ,Regression, Neural Network etc. For this report we will use one layered neural network.The task of recognizing an image of digit is very simple to our brain, but if we were to design a brain like structure made up of neurons which doesn't only recognize the image of digit but also improves itself to optimize future tasks, is quite complex.Our objective is to design such a system.\n",
    "\n",
    "#### <font color=navy>  Neural Network </font>\n",
    "Artificial neural network or Neural Network is the brain like structure of code made up of thousands of neurons each holding some small value. The decisions in such structures are made from the values of all the neurons.Also,values of these neurons changes with every new information that we feed. So in a way they are adapting to the new changes and hence learning it self.\n",
    "\n",
    "#### <font color=navy>  Skeleton of the report </font>\n",
    "To begin with we have around 60000 images of handwritten digits from mnist dataset. We will feed this images into a Neural Network.First layer is the input layer , which pre-process the image and pass it onto a hidden layer. This hidden layer uses the previously stored information to make the best prediction about the image and lights up a specific neuron in output layer to display the result.We will then use back propagation to change the values in the neuron in the hidden layer that will be used to make decisions about future images.Refer following image :\n",
    "![skeleton](skeleton.png)\n",
    "## <font color=navy> ll. Importing necessary packages </font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image   # For handling image related task. such as open,preview and create image. \n",
    "import glob  # Used for retriving all the file using matching certain pattern.\n",
    "import numpy as np  # Add various features for array , matrices and other high-level mathematics functions.\n",
    "import matplotlib.pyplot as plt  # Pythons 2D plotting Library for plotting graphs\n",
    "import mnist # used for importing handwritten images from mnist dataset\n",
    "import pandas # just to display it nicely in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=navy>III. Input of Neural Network </font>\n",
    "\n",
    "Each pixel represent neuron and the gray color value of pixels represents values of neuron.We will reshape the initial pixel matrix of the image to get a resultant matrix with each column containing pixels of one image and with total columns equal to total number of images. Below diagram illustrate that. \n",
    "![Input_Layer](Input_Layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images selected:  60000\n",
      "Height of image in pixels :28  \n",
      "Width of image in pixels  :28\n"
     ]
    }
   ],
   "source": [
    "training_images = mnist.train_images() # loading training data from mnist\n",
    "ytrue = training_label = mnist.train_labels() # loading training image labels from mnist\n",
    "totimages,h,w = training_images.shape # get the shape of the images\n",
    "X = (training_images.reshape((totimages, h*w))).T # initialize the Input matrix of the neural network\n",
    "X = X /  X.sum() \n",
    "print(\"Total number of images selected: \",totimages)\n",
    "print(f'Height of image in pixels :{h}  \\nWidth of image in pixels  :{w}')\n",
    "selection = (np.unique(training_label)).tolist() # list of selected characters\n",
    "c = len(selection)  # total number of classes or characters that we will be recognizing from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=navy> IV. Hidden Layer of the Neural Network </font>\n",
    "\n",
    "Hidden layer is the backbone of the whole neural network.Neural Networks learns by storing a matrix which will be used to determine the class of future images.Let's call this matrix <b> Weighted Matrix</b> or <b> WT</b>. We will first initialize WT as a some random values.Since this matrix will be used to predict the future outcomes it should be updated every time we feed a new image. This update will be made such that there is least possible error in the future classifications. And to determine that we need to find the error in the first classification or <b> Loss</b>. \n",
    "\n",
    "### <font color=navy> i. Weighted Matrix </font>\n",
    "\n",
    "This weighted matrix will have total rows equal to number of classifications with each row having weighted values of pixels for each class. Basically WT can be considered as the blueprint of images of all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of WT :  (10, 784)\n"
     ]
    }
   ],
   "source": [
    "WT = np.random.rand(c,(h*w))  # assign random values to WT matrix\n",
    "print('Shape of WT : ',WT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the DOT product of the weighted matrix WT and input matrix X. The result obtained(S) is the matrix having a specific value for every image with every classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the S : (10, 60000)\n",
      "S: \n",
      " [[9.33890260e-06 9.79187706e-06 6.20914977e-06 5.32628253e-06\n",
      "  7.19223864e-06]\n",
      " [8.96764216e-06 9.56725027e-06 6.50188017e-06 5.73326693e-06\n",
      "  7.63343088e-06]\n",
      " [9.24202595e-06 1.07249542e-05 6.56055022e-06 5.83989217e-06\n",
      "  7.92045634e-06]\n",
      " [8.55310472e-06 9.28129739e-06 6.10099825e-06 5.51823676e-06\n",
      "  7.39598525e-06]\n",
      " [9.87848139e-06 1.02854898e-05 6.07185639e-06 5.88894005e-06\n",
      "  7.86740138e-06]]\n"
     ]
    }
   ],
   "source": [
    "S = np.dot(WT,X) \n",
    "print(\"Shape of the S :\" ,S.shape)\n",
    "print(\"S: \\n\",S[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the softmax function on S. \n",
    "### <font color=navy> ii. Softmax Function and prediction </font>\n",
    "\n",
    "Softmax or normalized exponential function squashes the values of S into range (0,1). Hence this matrix can be considered as a probability matrix.Softmax is then used for multiclass classification to predicted class for each images and calculate Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): # Defining Softmax function \n",
    "    expx = np.exp(x)\n",
    "    return expx/expx.sum(axis=0) \n",
    "\n",
    "P = softmax(S) # Applying Softmax on S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in P will have a highest probability for a particular classification.This classification will be our predicated class for that image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = np.argmax(P,axis=0) # get predicted class for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's compare some values of true classification(ytrue) and predicted class(ypred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[4 2 2 4 2 2 5 4 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(ytrue[:10]) # true classes for each image\n",
    "print(ypred[:10]) # predicted classes for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix defined below helps see the classification and true class for all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(ytrue,ypred,classnames):\n",
    "    c = len(classnames)\n",
    "    cm = np.zeros((c,c),dtype=int)\n",
    "    for i,j in zip(ypred,ytrue):\n",
    "        cm[i,j] += 1\n",
    "    cmp = pandas.DataFrame(cm)\n",
    "    cmp.columns = pandas.MultiIndex.from_tuples([('true class'  ,char)   for char in classnames])\n",
    "    cmp.index   = pandas.MultiIndex.from_tuples([('classification',char) for char in classnames])\n",
    "    return cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">true class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">classification</th>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>28</td>\n",
       "      <td>403</td>\n",
       "      <td>295</td>\n",
       "      <td>201</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>252</td>\n",
       "      <td>316</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>81</td>\n",
       "      <td>167</td>\n",
       "      <td>112</td>\n",
       "      <td>617</td>\n",
       "      <td>292</td>\n",
       "      <td>164</td>\n",
       "      <td>246</td>\n",
       "      <td>171</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2212</td>\n",
       "      <td>685</td>\n",
       "      <td>2619</td>\n",
       "      <td>676</td>\n",
       "      <td>1039</td>\n",
       "      <td>539</td>\n",
       "      <td>537</td>\n",
       "      <td>1813</td>\n",
       "      <td>1518</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2472</td>\n",
       "      <td>462</td>\n",
       "      <td>818</td>\n",
       "      <td>443</td>\n",
       "      <td>831</td>\n",
       "      <td>258</td>\n",
       "      <td>2201</td>\n",
       "      <td>1126</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>166</td>\n",
       "      <td>337</td>\n",
       "      <td>879</td>\n",
       "      <td>1003</td>\n",
       "      <td>131</td>\n",
       "      <td>306</td>\n",
       "      <td>726</td>\n",
       "      <td>148</td>\n",
       "      <td>239</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>86</td>\n",
       "      <td>168</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2350</td>\n",
       "      <td>2698</td>\n",
       "      <td>354</td>\n",
       "      <td>1366</td>\n",
       "      <td>1894</td>\n",
       "      <td>1897</td>\n",
       "      <td>2616</td>\n",
       "      <td>928</td>\n",
       "      <td>1522</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>138</td>\n",
       "      <td>300</td>\n",
       "      <td>307</td>\n",
       "      <td>1352</td>\n",
       "      <td>1247</td>\n",
       "      <td>963</td>\n",
       "      <td>398</td>\n",
       "      <td>578</td>\n",
       "      <td>804</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>654</td>\n",
       "      <td>62</td>\n",
       "      <td>751</td>\n",
       "      <td>487</td>\n",
       "      <td>175</td>\n",
       "      <td>365</td>\n",
       "      <td>946</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true class                                                  \\\n",
       "                          0     1     2     3     4     5     6     7     8   \n",
       "classification 0        212    28   403   295   201   110    92   252   316   \n",
       "               1        112    81   167   112   617   292   164   246   171   \n",
       "               2       2212   685  2619   676  1039   539   537  1813  1518   \n",
       "               3          4    75    15     3    40    32    13    27    12   \n",
       "               4         26  2472   462   818   443   831   258  2201  1126   \n",
       "               5        166   337   879  1003   131   306   726   148   239   \n",
       "               6         49     4     1    19    55    86   168    67    11   \n",
       "               7       2350  2698   354  1366  1894  1897  2616   928  1522   \n",
       "               8        138   300   307  1352  1247   963   398   578   804   \n",
       "               9        654    62   751   487   175   365   946     5   132   \n",
       "\n",
       "                        \n",
       "                     9  \n",
       "classification 0   222  \n",
       "               1   194  \n",
       "               2  1088  \n",
       "               3    31  \n",
       "               4  1196  \n",
       "               5    73  \n",
       "               6    41  \n",
       "               7  2018  \n",
       "               8  1056  \n",
       "               9    30  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrue,ypred,selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that almost all the predicted classifications are wrong. This is because our weighted matrix is made up of just random values.\n",
    "\n",
    "\n",
    "### <font color=navy> iii. Loss </font>\n",
    "\n",
    "Now we will try to train neural network and change the values of WT to get the correct classifications. To train the network , we first need to find the loss in our current predictions. Loss in the current prediction is the sum of loss of each image. This can be done by first taking out probability of each true class and then perform a negative cross entropy. The total sum of all the values of this cross entropy is the total loss in our current prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 138155.1081302953\n"
     ]
    }
   ],
   "source": [
    "Pyi = P[ ytrue, np.arange(totimages) ]  # select the prob of the true class\n",
    "li = -np.log(Pyi)           # cross-entropy\n",
    "L = li.sum()                # this is the loss\n",
    "print(\"Loss :\",L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is very high. We aim to reduce this loss.\n",
    "\n",
    "### <font color=navy> iv. Backward Propagation </font>\n",
    "\n",
    "We now find the gradient of the loss. To do this we need to find the partial derivative of Loss(L) with respect to partial derivative of WT. We apply chain rule to find derivatives of each steps involves in finding the loss. In a way we are propagating backwards.we will then update the value of WT according to the stepsize that we that for the gradient decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the gradient of Loss (L):  0.5061526891229882\n"
     ]
    }
   ],
   "source": [
    "dLdli = np.ones_like(li)   \n",
    "dLdP = np.zeros_like(P)                     # most will be zero\n",
    "dLdP[ ytrue, np.arange(totimages) ] = dLdli * (-1/Pyi)  # modify the non-zero element in each row (see fancy indexing note below)\n",
    "dLdS = np.zeros_like(S)\n",
    "for m in range(c):             # apply the formula you derived for the derivatives of the softmax function last class\n",
    "    dLdS += dLdP[m]*(-P[m]*P)  # the \"j!=m\" terms\n",
    "dLdS += dLdP*P                 # the \"j=m\" term\n",
    "dLdWT = np.dot(dLdS,X.T)  # finally, this is the gradient of the loss\n",
    "\n",
    "print(\"Sum of the gradient of Loss (L): \",abs(dLdWT).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=navy> IV. Training our Neural Network </font>\n",
    "\n",
    "We found the gradient of Loss. Now we have to apply this changes to WT with some step size. Below are two functions that we will use for finding loss and loading image data. These functions are actually made form all the previous code we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(WT,X,y):\n",
    "    \n",
    "    nimages = X.shape[1]\n",
    "    \n",
    "    # forward pass to compute the loss\n",
    "\n",
    "    c = WT.shape[0]           # number of classes\n",
    "    S = np.dot(WT,X)\n",
    "    P = softmax(S)\n",
    "    Pyi = P[ y, np.arange(nimages) ]  # select the prob of the true class\n",
    "    li = -np.log(Pyi)           # cross-entropy\n",
    "    L = li.sum()                # this is the loss\n",
    "    \n",
    "    ypred = np.argmax(P,axis=0)\n",
    "    \n",
    "    # back-prop of the gradient of the loss\n",
    "\n",
    "    dLdli = np.ones_like(li)\n",
    "    dLdP = np.zeros_like(P)                     # most will be zero\n",
    "    dLdP[ y, np.arange(nimages) ] = dLdli * (-1/Pyi)  # modify the non-zero element in each row (see fancy indexing note below)\n",
    "    dLdS = np.zeros_like(S)\n",
    "    for m in range(c):             # apply the formula you derived for the derivatives of the softmax function last class\n",
    "        dLdS += dLdP[m]*(-P[m]*P)  # the \"j!=m\" terms\n",
    "    dLdS += dLdP*P                 # the \"j=m\" term\n",
    "    dLdWT = np.dot(dLdS,X.T)  # finally, this is the gradient of the loss\n",
    "    \n",
    "    return L,dLdWT,ypred\n",
    "\n",
    "def load_data(NN_images,NN_label):\n",
    "    ytrue = NN_label\n",
    "    totimages,h,w = NN_images.shape \n",
    "    X = (NN_images.reshape((totimages, h*w))).T\n",
    "    X = X /  X.sum()\n",
    "    print(\"Total number of images selected: \",totimages)\n",
    "    print(f'Height of image in pixels :{h}  \\nWidth of image in pixels  :{w}')\n",
    "    return X,ytrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=navy> i. Initial Loss and Confusion Matrix </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images selected:  60000\n",
      "Height of image in pixels :28  \n",
      "Width of image in pixels  :28\n",
      "Loss:  138155.10449059185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">true class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">classification</th>\n",
       "      <th>0</th>\n",
       "      <td>1121</td>\n",
       "      <td>36</td>\n",
       "      <td>334</td>\n",
       "      <td>298</td>\n",
       "      <td>647</td>\n",
       "      <td>1337</td>\n",
       "      <td>567</td>\n",
       "      <td>428</td>\n",
       "      <td>713</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499</td>\n",
       "      <td>4237</td>\n",
       "      <td>721</td>\n",
       "      <td>1119</td>\n",
       "      <td>1218</td>\n",
       "      <td>1009</td>\n",
       "      <td>356</td>\n",
       "      <td>1521</td>\n",
       "      <td>972</td>\n",
       "      <td>1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>514</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>481</td>\n",
       "      <td>15</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1086</td>\n",
       "      <td>1514</td>\n",
       "      <td>2848</td>\n",
       "      <td>479</td>\n",
       "      <td>328</td>\n",
       "      <td>593</td>\n",
       "      <td>2001</td>\n",
       "      <td>606</td>\n",
       "      <td>1194</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589</td>\n",
       "      <td>2</td>\n",
       "      <td>379</td>\n",
       "      <td>29</td>\n",
       "      <td>295</td>\n",
       "      <td>106</td>\n",
       "      <td>147</td>\n",
       "      <td>105</td>\n",
       "      <td>60</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>193</td>\n",
       "      <td>69</td>\n",
       "      <td>106</td>\n",
       "      <td>507</td>\n",
       "      <td>63</td>\n",
       "      <td>439</td>\n",
       "      <td>745</td>\n",
       "      <td>76</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>474</td>\n",
       "      <td>35</td>\n",
       "      <td>195</td>\n",
       "      <td>524</td>\n",
       "      <td>173</td>\n",
       "      <td>293</td>\n",
       "      <td>97</td>\n",
       "      <td>168</td>\n",
       "      <td>254</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>496</td>\n",
       "      <td>69</td>\n",
       "      <td>227</td>\n",
       "      <td>94</td>\n",
       "      <td>292</td>\n",
       "      <td>1485</td>\n",
       "      <td>51</td>\n",
       "      <td>210</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>513</td>\n",
       "      <td>334</td>\n",
       "      <td>1279</td>\n",
       "      <td>2895</td>\n",
       "      <td>2212</td>\n",
       "      <td>1073</td>\n",
       "      <td>460</td>\n",
       "      <td>2777</td>\n",
       "      <td>2354</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1416</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>298</td>\n",
       "      <td>261</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true class                                                  \\\n",
       "                          0     1     2     3     4     5     6     7     8   \n",
       "classification 0       1121    36   334   298   647  1337   567   428   713   \n",
       "               1        499  4237   721  1119  1218  1009   356  1521   972   \n",
       "               2          7    19    15    15   514    18    11   481    15   \n",
       "               3       1086  1514  2848   479   328   593  2001   606  1194   \n",
       "               4        589     2   379    29   295   106   147   105    60   \n",
       "               5        193    69   106   507    63   439   745    76    41   \n",
       "               6        474    35   195   524   173   293    97   168   254   \n",
       "               7         25   496    69   227    94   292  1485    51   210   \n",
       "               8        513   334  1279  2895  2212  1073   460  2777  2354   \n",
       "               9       1416     0    12    38   298   261    49    52    38   \n",
       "\n",
       "                        \n",
       "                     9  \n",
       "classification 0   563  \n",
       "               1  1734  \n",
       "               2   254  \n",
       "               3   246  \n",
       "               4   358  \n",
       "               5    20  \n",
       "               6   210  \n",
       "               7    52  \n",
       "               8  2400  \n",
       "               9   112  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WT = np.random.rand(c,h*w)  \n",
    "X,ytrue = load_data(training_images,training_label)\n",
    "L,dLdT,ypred = loss(WT,X,ytrue)\n",
    "cmp = confusion_matrix(ytrue,ypred,selection)\n",
    "print(\"Loss: \",L)\n",
    "cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=navy> ii. Training Neural Network </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT = np.random.rand(c,h*w)  \n",
    "TrainLosses = [] # store the losses of training images at each iterations\n",
    "iterations = [] # store all the iterations\n",
    "TrainPerc = [] # Stores the percentage of accuracy at each iteration\n",
    "TestLosses = [] # Store the losses of test images\n",
    "TestPerc = [] # store the percentage of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data: \n",
      "Total number of images selected:  60000\n",
      "Height of image in pixels :28  \n",
      "Width of image in pixels  :28\n",
      "Loading Test Data: \n",
      "Total number of images selected:  10000\n",
      "Height of image in pixels :28  \n",
      "Width of image in pixels  :28\n",
      "iteration 0) L 128246.49494950613     67 %\n",
      "iteration 100) L 31411.986074561748     87 %\n",
      "iteration 200) L 26200.52935124514     88 %\n",
      "iteration 300) L 24015.49596884448     89 %\n",
      "iteration 400) L 22741.383437209464     89 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">true class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">classification</th>\n",
       "      <th>0</th>\n",
       "      <td>5695</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6515</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>5161</td>\n",
       "      <td>142</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>5335</td>\n",
       "      <td>5</td>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>5341</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>253</td>\n",
       "      <td>5</td>\n",
       "      <td>4441</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>44</td>\n",
       "      <td>66</td>\n",
       "      <td>114</td>\n",
       "      <td>5588</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>113</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>34</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>174</td>\n",
       "      <td>140</td>\n",
       "      <td>46</td>\n",
       "      <td>237</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "      <td>5021</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "      <td>279</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>104</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true class                                                  \\\n",
       "                          0     1     2     3     4     5     6     7     8   \n",
       "classification 0       5695     1    51    28    13   103    41    45    32   \n",
       "               1          0  6515    70    34    32    56    23    79   162   \n",
       "               2         28    32  5161   142    42    43    64    98    82   \n",
       "               3         16    30    96  5335     5   227     6    25   165   \n",
       "               4         13     6   122     6  5341    78    50    78    26   \n",
       "               5         40    41    18   253     5  4441    88    10   179   \n",
       "               6         53     9   116    44    66   114  5588     3    46   \n",
       "               7          5    16   113    76    13    31     2  5686    34   \n",
       "               8         65    83   174   140    46   237    53    19  5021   \n",
       "               9          8     9    37    73   279    91     3   222   104   \n",
       "\n",
       "                        \n",
       "                     9  \n",
       "classification 0    43  \n",
       "               1    35  \n",
       "               2    35  \n",
       "               3    98  \n",
       "               4   219  \n",
       "               5    41  \n",
       "               6     5  \n",
       "               7   194  \n",
       "               8    56  \n",
       "               9  5223  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = mnist.test_images()\n",
    "test_label = mnist.test_labels()\n",
    "\n",
    "print(\"Loading Training Data: \")\n",
    "X,ytrue = load_data(training_images,training_label) \n",
    "print(\"Loading Test Data: \")\n",
    "Xtest,ytesttrue = load_data(test_images,test_label)\n",
    "L,gradL,ypred = loss(WT,X,ytrue)\n",
    "stepsize = 1e8 # stepsize\n",
    "\n",
    "for i in range(500):  # number of iterations\n",
    "    iterations.append(i) # store the iteration\n",
    "    WT += -stepsize*gradL # update the WT with stepisze and gradient of L . negative sign indicates lower decent\n",
    "    L,gradL,ypred = loss(WT,X,ytrue)\n",
    "    Ltest,gradLtest,ypredtest = loss (WT,Xtest,ytesttrue)\n",
    "    TrainLosses.append(L)\n",
    "    TestLosses.append(Ltest)\n",
    "    train_correct_percentage = int(100*(ypred==ytrue).sum()/len(ytrue)) \n",
    "    test_correct_percentage = int(100*(ypredtest==ytesttrue).sum()/len(ytesttrue))\n",
    "    if(i%100 == 0): print(f\"iteration {i}) L\",L , \"   \" ,train_correct_percentage,'%')\n",
    "    TestPerc.append(test_correct_percentage)   \n",
    "    TrainPerc.append(train_correct_percentage)\n",
    "    \n",
    "cmp = confusion_matrix(ytrue,ypred,selection)\n",
    "cmp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with every iterations the Loss is decreasing and the Accuracy of the Prediction is increasing. Also, Look at the confusion matrix now. We can clearly see that majority of the classifications are correct. If we were to run the code again accuracy of the Neural Network will increase. Hence, there we have a system that learns itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=navy> iii. Testing Neural Network on Test Images </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L 8815.559503599823     90 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">true class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">classification</th>\n",
       "      <th>0</th>\n",
       "      <td>957</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1103</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>896</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>907</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>923</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>843</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true class                                              \n",
       "                          0     1    2    3    4    5    6    7    8    9\n",
       "classification 0        957     0   11    5    1   14   16    3    9   10\n",
       "               1          0  1103    6    0    4    5    3   19    9    7\n",
       "               2          3     2  896   18    5    4    5   28    9    5\n",
       "               3          2     4   16  904    1   41    2    4   27   10\n",
       "               4          0     1   15    1  907   13   13   11    8   43\n",
       "               5          3     2    0   32    0  741   16    0   27   13\n",
       "               6         10     4   15    3   11   16  898    0   13    0\n",
       "               7          1     1   20   15    1   10    1  923   15   25\n",
       "               8          4    18   45   21    8   40    4    3  843    8\n",
       "               9          0     0    8   11   44    8    0   37   14  888"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltest,gradLtest,ypredtest = loss(WT,Xtest,ytesttrue)\n",
    "\n",
    "test_correct_percentage = int(100*(ypredtest==ytesttrue).sum()/len(ytesttrue))\n",
    "print(\"L\",Ltest , \"   \" ,test_correct_percentage,'%')\n",
    "confusion_matrix(ytesttrue,ypredtest,selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our neural network is working very efficiently on our test data with accuracy of 90%. Now lets explore relation between accuracy of testing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,8))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(iterations, TrainLosses, 'g-')\n",
    "ax1.plot(iterations, TestLosses,'r-')\n",
    "ax2.plot(iterations, TrainPerc, 'b-')\n",
    "ax2.plot(iterations, TestPerc, 'y-')\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax2.set_ylabel('Accuracy (in percentage)')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=navy> V. Conclusion </font>\n",
    "\n",
    "We see that from around 300th iteration the difference between loss in training images and the test images is remaining almost constant from this point onwards even if we train our data more with the training images it will be over fitting of our training data. Which generally is not efficient for future image recognition. We also see that accuracy in the test images goes hand in hand with the accuracy of the training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=navy> VI. Reference </font>\n",
    "\n",
    "https://www.youtube.com/watch?v=aircAruvnKk\n",
    "\n",
    "https://en.wikipedia.org/wiki/Softmax_function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
